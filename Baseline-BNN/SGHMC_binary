{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yWu9OA-sRQ5NGpQq03kABcffQW9mo_x3","authorship_tag":"ABX9TyO5b3lW3Py7+tEKaZ3PANxZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Ghvs9n0f0Ik","executionInfo":{"status":"ok","timestamp":1696042367333,"user_tz":420,"elapsed":178,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}},"outputId":"99095a8b-5896-4bd9-b5b1-1576b13bbf85"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bayesian-Neural-Networks-master\n"]}],"source":["%cd /content/drive/MyDrive/Bayesian-Neural-Networks-master"]},{"cell_type":"code","source":["from __future__ import division, print_function\n","import time\n","import torch.utils.data\n","from torchvision import transforms, datasets\n","import argparse\n","import matplotlib\n","from src.Stochastic_Gradient_HMC_SA.model_binary import BNN_cat\n","from src.utils import *\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt"],"metadata":{"id":"2kV71ACDhfCE","executionInfo":{"status":"ok","timestamp":1696042374451,"user_tz":420,"elapsed":6402,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["parser = argparse.ArgumentParser(description='Train Bayesian Neural Net on MNIST with Scale-adapted Stochastic Gradient HMC')\n","parser.add_argument('--epochs', type=int, nargs='?', action='store', default=20,\n","                    help='How many epochs to train. Default: 20.')\n","parser.add_argument('--sample_freq', type=int, nargs='?', action='store', default=2,\n","                    help='How many epochs pass between saving samples. Default: 2.')\n","parser.add_argument('--burn_in', type=int, nargs='?', action='store', default=1,\n","                    help='How many epochs to burn in for?. Default: 20.')\n","parser.add_argument('--lr', type=float, nargs='?', action='store', default=1e-2,\n","                    help='learning rate. I recommend 1e-2. Default: 1e-2.')\n","parser.add_argument('--models_dir', type=str, nargs='?', action='store', default='SGHMC_models',\n","                    help='Where to save learnt weights and train vectors. Default: \\'SGHMC_models\\'.')\n","parser.add_argument('--results_dir', type=str, nargs='?', action='store', default='SGHMC_results',\n","                    help='Where to save learnt training plots. Default: \\'SGHMC_results\\'.')\n","args = parser.parse_args(args=[])"],"metadata":{"id":"9DMsZ6Tuhg_E","executionInfo":{"status":"ok","timestamp":1696042377497,"user_tz":420,"elapsed":139,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Where to save models weights\n","models_dir = args.models_dir\n","# Where to save plots and error, accuracy vectors\n","results_dir = args.results_dir\n","\n","mkdir(models_dir)\n","mkdir(results_dir)\n","# ------------------------------------------------------------------------------------------------------\n","# train config\n","NTrainPoints = 800\n","batch_size = 32\n","nb_epochs = args.epochs\n","log_interval = 1\n","nb_its_dev = log_interval\n","flat_ims=True\n","# ------------------------------------------------------------------------------------------------------\n","# dataset\n","cprint('c', '\\nData:')\n","\n","# load data\n","\n","class CustomNNDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        x = self.x[idx]\n","        y = self.y[idx]\n","        return x, y\n","\n","with open(os.path.join('./binary_nn/nn.pickle'), 'rb') as f:\n","  [pr_cov,x,true_input,y] = pickle.load(f)\n","\n","use_cuda = torch.cuda.is_available()\n","\n","\n","x = torch.from_numpy(x).type(torch.float)\n","y = torch.from_numpy(y).type(torch.int).reshape(y.shape[0],)\n","\n","# split the data into training and validation sets\n","x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","# define the train and validation sets\n","train_dataset = CustomNNDataset(x_train, y_train)\n","val_dataset = CustomNNDataset(x_val, y_val)\n","all_dataset = CustomNNDataset(x, y)\n","\n","# test set\n","with open(os.path.join('./binary_nn/nn_test.pickle'), 'rb') as f:\n","  [pr_cov_test,x_test,true_input_test,y_test] = pickle.load(f)\n","x_test = torch.from_numpy(x_test).type(torch.float)\n","y_test = torch.from_numpy(y_test).type(torch.int).reshape(y_test.shape[0],)\n","test_dataset = CustomNNDataset(x_test, y_test)\n","\n","\n","if use_cuda:\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True,\n","                                              num_workers=3)\n","    valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True,\n","                                            num_workers=3)\n","\n","else:\n","    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False,\n","                                              num_workers=3)\n","    valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=False,\n","                                            num_workers=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhtXhW3HiBv8","executionInfo":{"status":"ok","timestamp":1696042403853,"user_tz":420,"elapsed":750,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}},"outputId":"2465c0dd-2190-4819-814c-4782f56302e5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[36m\n","Data:\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["## ---------------------------------------------------------------------------------------------------------------------\n","# net dims\n","cprint('c', '\\nNetwork:')\n","\n","lr = args.lr\n","########################################################################################\n","\n","\n","net = BNN_cat(NTrainPoints, lr=lr, cuda=use_cuda, grad_std_mul=20)\n","\n","\n","## weight saving parameters #######\n","burn_in = args.burn_in\n","sim_steps = args.sample_freq\n","N_saves=100000\n","resample_its = 50\n","resample_prior_its = 15\n","re_burn = 1e8\n","###################################\n","\n","## ---------------------------------------------------------------------------------------------------------------------\n","\n","\n","\n","# net dims\n","epoch = 0\n","it_count = 0\n","## ---------------------------------------------------------------------------------------------------------------------\n","# train\n","cprint('c', '\\nTrain:')\n","\n","print('  init cost variables:')\n","cost_train = np.zeros(nb_epochs)\n","err_train = np.zeros(nb_epochs)\n","cost_dev = np.zeros(nb_epochs)\n","err_dev = np.zeros(nb_epochs)\n","best_cost = np.inf\n","best_err = np.inf\n","test_accuracy_dev = np.zeros(nb_epochs)\n","\n","tic0 = time.time()\n","for i in range(epoch, nb_epochs):\n","    net.set_mode_train(True)\n","    tic = time.time()\n","    nb_samples = 0\n","    for x, y in trainloader:\n","\n","        if flat_ims:\n","            x = x.view(x.shape[0], -1)\n","            y = y.unsqueeze(1)\n","\n","        cost_pred, err = net.fit(x, y, burn_in=(i % re_burn < burn_in),\n","                                 resample_momentum=(it_count % resample_its == 0),\n","                                 resample_prior=(it_count % resample_prior_its == 0))\n","        it_count += 1\n","        err_train[i] += err\n","        cost_train[i] += cost_pred\n","        nb_samples += len(x)\n","\n","    cost_train[i] /= nb_samples\n","    err_train[i] /= nb_samples\n","    toc = time.time()\n","\n","    # ---- print\n","    print(\"it %d/%d, Jtr_pred = %f, err = %f, \" % (i, nb_epochs, cost_train[i], err_train[i]), end=\"\")\n","    cprint('r', '   time: %f seconds\\n' % (toc - tic))\n","    net.update_lr(i)\n","\n","    # ---- save weights\n","    if i % re_burn >= burn_in and i % sim_steps == 0:\n","        net.save_sampled_net(max_samples=N_saves)\n","\n","    # ---- dev\n","    if i % nb_its_dev == 0:\n","        nb_samples = 0\n","        for j, (x, y) in enumerate(valloader):\n","            if flat_ims:\n","                x = x.view(x.shape[0], -1)\n","                y = y.unsqueeze(1)\n","\n","            cost, err, probs = net.eval(x, y)\n","\n","            cost_dev[i] += cost\n","            err_dev[i] += err\n","            nb_samples += len(x)\n","\n","        cost_dev[i] /= nb_samples\n","        err_dev[i] /= nb_samples\n","\n","        cprint('g', '    Jdev = %f, err = %f\\n' % (cost_dev[i], err_dev[i]))\n","        if err_dev[i] < best_err:\n","            best_err = err_dev[i]\n","            cprint('b', 'best test error')\n","    # test_accuracy = ((net.predict(test_dataset.x)>.5).int().flatten() == test_dataset.y).double().mean().numpy()\n","    test_accuracy = 1 - net.eval(test_dataset.x, test_dataset.y.unsqueeze(1))[1].numpy() / test_dataset.y.shape[0]\n","    test_accuracy_dev[i] = test_accuracy\n","\n","toc0 = time.time()\n","runtime_per_it = (toc0 - tic0) / float(nb_epochs)\n","runtime_total = toc0 - tic0\n","cprint('r', '   average time: %f seconds\\n' % runtime_per_it)\n","cprint('r', '   total time: %f seconds\\n' % runtime_total)\n","\n","## SAVE WEIGHTS\n","net.save_weights(models_dir + '/state_dicts.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0AlfdUpZf6Lc","executionInfo":{"status":"ok","timestamp":1696042415338,"user_tz":420,"elapsed":9286,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}},"outputId":"7d182fff-54a9-4bc8-85a3-f5fabfa9347e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[36m\n","Network:\u001b[0m\n","\u001b[36m\n","Net:\u001b[0m\n","\u001b[33mBNN categorical output\u001b[0m\n","    Total params: 0.00M\n","\u001b[36m\n","Train:\u001b[0m\n","  init cost variables:\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Bayesian-Neural-Networks-master/src/Stochastic_Gradient_HMC_SA/optimizers.py:69: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n","  d_p.add_(weight_decay, p.data)\n"]},{"output_type":"stream","name":"stdout","text":["it 0/20, Jtr_pred = 0.681075, err = 0.477500, \u001b[31m   time: 0.374421 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.662715, err = 0.470000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 1/20, Jtr_pred = 0.594686, err = 0.297500, \u001b[31m   time: 0.281542 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.391454, err = 0.165000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 2/20, Jtr_pred = 0.339717, err = 0.097500, \u001b[31m   time: 0.263790 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 1/100000\u001b[0m\n","\u001b[32m    Jdev = 0.284066, err = 0.100000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 3/20, Jtr_pred = 0.229765, err = 0.056250, \u001b[31m   time: 0.241891 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.151287, err = 0.045000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 4/20, Jtr_pred = 0.171799, err = 0.048750, \u001b[31m   time: 0.214871 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 2/100000\u001b[0m\n","\u001b[32m    Jdev = 0.193697, err = 0.075000\n","\u001b[0m\n","it 5/20, Jtr_pred = 0.162185, err = 0.053750, \u001b[31m   time: 0.347230 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.192248, err = 0.060000\n","\u001b[0m\n","it 6/20, Jtr_pred = 0.151428, err = 0.042500, \u001b[31m   time: 0.356643 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 3/100000\u001b[0m\n","\u001b[32m    Jdev = 0.144228, err = 0.040000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 7/20, Jtr_pred = 0.157328, err = 0.042500, \u001b[31m   time: 0.348627 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.162400, err = 0.060000\n","\u001b[0m\n","it 8/20, Jtr_pred = 0.146111, err = 0.040000, \u001b[31m   time: 0.339967 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 4/100000\u001b[0m\n","\u001b[32m    Jdev = 0.137599, err = 0.050000\n","\u001b[0m\n","it 9/20, Jtr_pred = 0.174848, err = 0.047500, \u001b[31m   time: 0.327803 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.252352, err = 0.105000\n","\u001b[0m\n","it 10/20, Jtr_pred = 0.163843, err = 0.043750, \u001b[31m   time: 0.353423 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 5/100000\u001b[0m\n","\u001b[32m    Jdev = 0.157758, err = 0.060000\n","\u001b[0m\n","it 11/20, Jtr_pred = 0.166475, err = 0.042500, \u001b[31m   time: 0.416196 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.111639, err = 0.040000\n","\u001b[0m\n","it 12/20, Jtr_pred = 0.147055, err = 0.036250, \u001b[31m   time: 0.280635 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 6/100000\u001b[0m\n","\u001b[32m    Jdev = 0.128085, err = 0.030000\n","\u001b[0m\n","\u001b[34mbest test error\u001b[0m\n","it 13/20, Jtr_pred = 0.151904, err = 0.038750, \u001b[31m   time: 0.247030 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.117197, err = 0.040000\n","\u001b[0m\n","it 14/20, Jtr_pred = 0.150995, err = 0.038750, \u001b[31m   time: 0.226588 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 7/100000\u001b[0m\n","\u001b[32m    Jdev = 0.119696, err = 0.035000\n","\u001b[0m\n","it 15/20, Jtr_pred = 0.145340, err = 0.041250, \u001b[31m   time: 0.227866 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.121036, err = 0.040000\n","\u001b[0m\n","it 16/20, Jtr_pred = 0.148652, err = 0.040000, \u001b[31m   time: 0.250112 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 8/100000\u001b[0m\n","\u001b[32m    Jdev = 0.122908, err = 0.045000\n","\u001b[0m\n","it 17/20, Jtr_pred = 0.154181, err = 0.038750, \u001b[31m   time: 0.233119 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.115707, err = 0.030000\n","\u001b[0m\n","it 18/20, Jtr_pred = 0.143927, err = 0.035000, \u001b[31m   time: 0.231709 seconds\n","\u001b[0m\n","\u001b[36m saving weight samples 9/100000\u001b[0m\n","\u001b[32m    Jdev = 0.152012, err = 0.050000\n","\u001b[0m\n","it 19/20, Jtr_pred = 0.156443, err = 0.042500, \u001b[31m   time: 0.255495 seconds\n","\u001b[0m\n","\u001b[32m    Jdev = 0.173879, err = 0.055000\n","\u001b[0m\n","\u001b[31m   average time: 0.455294 seconds\n","\u001b[0m\n","\u001b[31m   total time: 9.105875 seconds\n","\u001b[0m\n"]}]},{"cell_type":"code","source":["test_accuracy_dev"],"metadata":{"id":"is0ffhY3gWzK","executionInfo":{"status":"ok","timestamp":1696042418108,"user_tz":420,"elapsed":119,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ceda4333-3988-4f32-d3a6-1861cb9f9a4e"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.518, 0.809, 0.9  , 0.953, 0.919, 0.928, 0.947, 0.93 , 0.945,\n","       0.872, 0.938, 0.948, 0.955, 0.947, 0.95 , 0.945, 0.947, 0.959,\n","       0.936, 0.935])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"UR8oISnRlQRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yxLN4vY0lQTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(os.path.join('data.pickle'), 'rb') as f:\n","  [nz_var,pr_cov,x,true_input,y] = pickle.load(f)\n","\n","def true_forward(u, x):\n","  return 1 / (1 + np.exp(\n","      -np.dot(np.dot(np.dot(x, u[:15].reshape((3, 5))) + u[45:50], u[15:40].reshape((5, 5))) + u[50:55], u[40:45].reshape((5, 1))) - u[55:]\n","      ))\n","\n","fwdout = true_forward(true_input, x)\n","\n","epsilon=1e-8\n","np.sum(y * np.log(fwdout+epsilon) + (1 - y) * np.log(1 - fwdout+epsilon))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71UqwwrvlQVy","executionInfo":{"status":"ok","timestamp":1695012124049,"user_tz":420,"elapsed":156,"user":{"displayName":"Yang Meng","userId":"04956942467409089725"}},"outputId":"eba117d9-6481-4434-80be-9861d74d02ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-165.12137255394214"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":[],"metadata":{"id":"zuOOJ7IDl4Yv"},"execution_count":null,"outputs":[]}]}